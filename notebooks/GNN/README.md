# ğŸ§  Graph Neural Networks for Movie Recommendation

A comprehensive learning guide for implementing GNN-based recommendation systems, building upon the existing collaborative filtering approach.

## ğŸ“š Table of Contents

1. [Overview](#overview)
2. [Why GNNs for Recommendations?](#why-gnns-for-recommendations)
3. [Concepts Explained](#concepts-explained)
4. [GNN Architectures](#gnn-architectures)
5. [Installation](#installation)
6. [Project Structure](#project-structure)
7. [Quick Start](#quick-start)
8. [Evaluation Metrics](#evaluation-metrics)
9. [Comparison: MF vs GNN](#comparison-mf-vs-gnn)
10. [Next Steps](#next-steps)
11. [References](#references)

---

## Overview

This module explores **Graph Neural Networks (GNNs)** as an evolution from traditional matrix factorization for movie recommendations. GNNs model user-movie interactions as a graph, enabling richer representations and better capturing of complex relationships.

### What's Included

| File | Description |
|------|-------------|
| `GNN_Movie_Recommendation_Learning.ipynb` | Complete learning notebook with implementations |
| `README.md` | This documentation |
| `requirements.txt` | Python dependencies |

---

## Why GNNs for Recommendations?

### The Graph Perspective

Traditional collaborative filtering treats user-item interactions as a matrix. GNNs view it as a **graph**:

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚         User-Movie Graph             â”‚
      â”‚                                      â”‚
      â”‚   Userâ‚ â”€â”€(4.5)â”€â”€â–º Movieâ‚ â—„â”€â”€(3.0)â”€â”€ Userâ‚‚
      â”‚     â”‚               â”‚                  â”‚
      â”‚   (5.0)           (similar)          (4.0)
      â”‚     â”‚               â”‚                  â”‚
      â”‚     â–¼               â–¼                  â–¼
      â”‚   Movieâ‚‚ â—„â”€â”€â”€â”€â”€â”€â”€â–º Movieâ‚ƒ â—„â”€â”€â”€â”€â”€â”€â”€â–º Movieâ‚„
      â”‚                                      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Advantages of GNNs

| Aspect | Matrix Factorization | GNN Approach |
|--------|---------------------|--------------|
| **Structure** | Flat user-item matrix | Rich graph with relationships |
| **Information Flow** | Direct interactions only | Multi-hop neighbor information |
| **Features** | Learned latent factors | Can incorporate side information |
| **Cold Start** | Limited (mean normalization) | Better (propagate from neighbors) |
| **Explainability** | Low | Can trace recommendation paths |
| **Scalability** | Excellent | Good (with sampling techniques) |

---

## Concepts Explained

### 1. Bipartite Graph

Our recommendation graph has two types of nodes:
- **User nodes**: Represent users
- **Movie nodes**: Represent movies
- **Edges**: Connect users to movies they've rated (edge weight = rating)

```python
# Example structure
Nodes: [Uâ‚, Uâ‚‚, Uâ‚ƒ, ..., Mâ‚, Mâ‚‚, Mâ‚ƒ, ...]
Edges: [(Uâ‚, Mâ‚, rating=4.5), (Uâ‚, Mâ‚ƒ, rating=5.0), ...]
```

### 2. Message Passing

GNNs learn through **message passing**:

1. **Aggregate**: Each node gathers information from neighbors
2. **Update**: Combine aggregated info with own features
3. **Repeat**: Stack multiple layers for multi-hop information

```
Layer 0: Node knows only itself
Layer 1: Node knows its direct neighbors
Layer 2: Node knows neighbors of neighbors
...
```

### 3. Graph Convolution

Similar to image convolution, but on graphs:

```
Image CNN:  pixel value = f(surrounding pixels)
Graph GNN:  node embedding = f(neighbor embeddings)
```

The key difference: graphs have **irregular structure** (variable number of neighbors).

---

## GNN Architectures

### 1. GCN (Graph Convolutional Network)

**Core idea**: Normalize and average neighbor features

```python
h_v = Ïƒ(W Â· MEAN({h_u : u âˆˆ N(v) âˆª {v}}))
```

**Pros**: Simple, effective
**Cons**: All neighbors weighted equally

### 2. GraphSAGE

**Core idea**: Sample and aggregate from neighbors

```python
h_v = Ïƒ(W Â· CONCAT(h_v, AGG({h_u : u âˆˆ sample(N(v))})))
```

**Pros**: Scalable (sampling), inductive learning
**Cons**: Information loss from sampling

### 3. GAT (Graph Attention Network)

**Core idea**: Learn attention weights for neighbors

```python
Î±_vu = attention(h_v, h_u)  # How important is u to v?
h_v = Ïƒ(Î£ Î±_vu Â· W Â· h_u)
```

**Pros**: Learns importance of neighbors
**Cons**: More parameters, computationally expensive

### 4. LightGCN â­ (Recommended for RecSys)

**Core idea**: Simplify GCN by removing unnecessary components

```python
# No feature transformation, no activation!
h_v^(k) = Î£ (1/âˆš|N(v)|âˆš|N(u)|) Â· h_u^(k-1)

# Final embedding: average across all layers
h_v = (h_v^(0) + h_v^(1) + ... + h_v^(K)) / (K+1)
```

**Pros**: Simple, fast, often best performance for recommendations
**Cons**: Limited expressiveness for complex features

### Architecture Comparison

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        GNN Architecture Complexity          â”‚
                    â”‚                                             â”‚
     Simple â—„â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â–º Complex
                    â”‚                                             â”‚
                    â”‚  LightGCN    GCN    GraphSAGE    GAT       â”‚
                    â”‚     â”‚         â”‚         â”‚         â”‚         â”‚
                    â”‚     â–¼         â–¼         â–¼         â–¼         â”‚
                    â”‚   Best for  Good     Scalable  Attention   â”‚
                    â”‚   RecSys   Baseline             -based     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Installation

### Prerequisites

- Python 3.8+
- CUDA (optional, for GPU acceleration)

### Install Dependencies

```bash
# Create virtual environment (recommended)
python -m venv gnn_env
source gnn_env/bin/activate  # Linux/Mac
# or: gnn_env\Scripts\activate  # Windows

# Install PyTorch (check https://pytorch.org for your CUDA version)
pip install torch torchvision

# Install PyTorch Geometric
pip install torch-geometric

# Install other dependencies
pip install -r requirements.txt
```

### Verify Installation

```python
import torch
from torch_geometric.nn import GCNConv

print(f"PyTorch: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print("PyTorch Geometric: OK")
```

---

## Project Structure

```
gnn_learning/
â”‚
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”‚
â”œâ”€â”€ GNN_Movie_Recommendation_Learning.ipynb  # Main learning notebook
â”‚                                            # - Data exploration
â”‚                                            # - Graph construction
â”‚                                            # - Model implementations
â”‚                                            # - Training & evaluation
â”‚                                            # - Visualizations
â”‚
â”œâ”€â”€ models/                                # (To be created)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ gcn.py
â”‚   â”œâ”€â”€ sage.py
â”‚   â”œâ”€â”€ gat.py
â”‚   â””â”€â”€ lightgcn.py
â”‚
â”œâ”€â”€ utils/                                 # (To be created)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â””â”€â”€ eval_utils.py
â”‚
â””â”€â”€ saved_models/                          # (Created after training)
    â””â”€â”€ lightgcn_model.pt
```

---

## Quick Start

### 1. Open the Notebook

```bash
jupyter notebook GNN_Movie_Recommendation_Learning.ipynb
```

### 2. Run All Cells

The notebook is self-contained and will:
- Load MovieLens data
- Build the user-movie graph
- Train multiple GNN models
- Compare performance
- Visualize embeddings

### 3. Key Outputs

After running, you'll see:
- Training curves for all models
- RMSE/MAE comparison table
- t-SNE embedding visualizations
- Sample recommendations

---

## Evaluation Metrics

### Rating Prediction Metrics

| Metric | Formula | Interpretation |
|--------|---------|----------------|
| **RMSE** | âˆš(Î£(y - Å·)Â² / n) | Penalizes large errors more |
| **MAE** | Î£\|y - Å·\| / n | Average absolute error |

### Ranking Metrics (Advanced)

| Metric | Description |
|--------|-------------|
| **Precision@K** | Fraction of top-K items that are relevant |
| **Recall@K** | Fraction of relevant items in top-K |
| **NDCG@K** | Considers ranking position |
| **Hit Rate** | Did the user's item appear in top-K? |

---

## Comparison: MF vs GNN

### Conceptual Differences

```
Matrix Factorization:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Matrix (U) Ã— Movie Matrix (M) â”‚
â”‚         â†“                           â”‚
â”‚     Rating Prediction               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Graph Neural Network:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Build User-Movie Graph             â”‚
â”‚         â†“                           â”‚
â”‚  Message Passing (Multiple Layers)  â”‚
â”‚         â†“                           â”‚
â”‚  Get Final Embeddings               â”‚
â”‚         â†“                           â”‚
â”‚     Rating Prediction               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Use What

| Scenario | Recommended Approach |
|----------|---------------------|
| Simple, fast baseline | Matrix Factorization |
| Rich side information | GNN with node features |
| Very sparse data | GNN (better propagation) |
| Real-time updates needed | MF (simpler to update) |
| Explainability required | GNN (trace paths) |
| Production at scale | LightGCN or MF |

---

## Next Steps

### For Learning
- [ ] Complete the notebook end-to-end
- [ ] Experiment with hyperparameters (embedding_dim, num_layers, lr)
- [ ] Try different train/test splits
- [ ] Add your own movie ratings and get recommendations

### For Integration
- [ ] Modularize code into separate Python files
- [ ] Create inference-only pipeline for Streamlit
- [ ] Add node features (genres, year, popularity)
- [ ] Implement efficient cold-start handling

### Advanced Topics
- [ ] Heterogeneous GNNs (multiple edge types)
- [ ] Knowledge Graph integration (actors, directors)
- [ ] Temporal dynamics (user preferences change over time)
- [ ] Contrastive learning for better representations

---

## References

### Papers

1. **LightGCN** (Recommended Reading)
   - He, X., et al. "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation." SIGIR 2020.
   - [Paper](https://arxiv.org/abs/2002.02126) | [Code](https://github.com/gusye1234/LightGCN-PyTorch)

2. **GCN** (Foundation)
   - Kipf, T. N., & Welling, M. "Semi-Supervised Classification with Graph Convolutional Networks." ICLR 2017.
   - [Paper](https://arxiv.org/abs/1609.02907)

3. **GraphSAGE**
   - Hamilton, W., et al. "Inductive Representation Learning on Large Graphs." NeurIPS 2017.
   - [Paper](https://arxiv.org/abs/1706.02216)

4. **GAT**
   - VeliÄkoviÄ‡, P., et al. "Graph Attention Networks." ICLR 2018.
   - [Paper](https://arxiv.org/abs/1710.10903)

### Tutorials & Resources

- [PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/)
- [Stanford CS224W: Machine Learning with Graphs](http://web.stanford.edu/class/cs224w/)
- [Distill.pub: Understanding Convolutions on Graphs](https://distill.pub/2021/understanding-gnns/)

### Dataset

- MovieLens Dataset: Harper, F. M., & Konstan, J. A. "The MovieLens Datasets: History and Context." ACM TIIS 2015.
- [Download](https://grouplens.org/datasets/movielens/)

---

## License

This learning module is part of the Movie Recommendation System project and follows the same MIT License.

---

## Questions?

Feel free to experiment, break things, and learn! The notebook includes detailed comments explaining each step.

**Happy Learning! ğŸ¬ğŸ§ **
