{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¬ GNN Architectures Deep Dive\n",
    "\n",
    "This is the first notebook for the GNN learning with movie dataset. In this notebook our aim is to see the big picture and understand the shapes of the data.\n",
    "\n",
    "## Understanding Layer-by-Layer with Shapes\n",
    "\n",
    "This notebook explains GNN architectures with input/output shapes at every layer.\n",
    "\n",
    "We will see how the data is transferred through GNN architecture. What are the shapes of the data in each layer? What do we achieve?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ The Big Picture: What Are We Computing?\n",
    "\n",
    "### The Two-Stage Process\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                                                             â”‚\n",
    "â”‚   STAGE 1: Learn Embeddings              STAGE 2: Predict Ratings           â”‚\n",
    "â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\n",
    "â”‚   â”‚   Graph     â”‚                        â”‚  User Embedding (64,)   â”‚        â”‚\n",
    "â”‚   â”‚   (Users +  â”‚ â”€â”€â”€â–º GNN Layers â”€â”€â”€â–º   â”‚          Ã—              â”‚ â”€â”€â”€â–º Rating (scalar)  â”‚\n",
    "â”‚   â”‚   Movies)   â”‚                        â”‚  Movie Embedding (64,)  â”‚        â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚   Output: Embeddings for ALL             Output: Single rating              â”‚\n",
    "â”‚   users and movies                       for one (user, movie) pair         â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### The GNN outputs embeddings, then we use those embeddings to predict ratings.\n",
    "\n",
    "1. **GNN Output**: Embeddings for EVERY user and EVERY movie\n",
    "2. **Final Prediction**: Dot product of (user_embedding, movie_embedding) â†’ rating\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Let's Define Our Example Dimensions\n",
    "\n",
    "For all examples in this notebook, we'll use:\n",
    "\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `num_users` | 610 | Number of users |\n",
    "| `num_movies` | 9,724 | Number of movies |\n",
    "| `num_nodes` | 10,334 | Total nodes (users + movies) |\n",
    "| `num_edges` | 100,836 | Number of ratings (edges) |\n",
    "| `embedding_dim` | 64 | Size of each embedding vector |\n",
    "| `num_layers` | 3 | Number of GNN layers |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T09:49:45.510484Z",
     "start_time": "2026-01-13T09:49:42.159484Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Our example dimensions\n",
    "NUM_USERS = 610\n",
    "NUM_MOVIES = 9724\n",
    "NUM_NODES = NUM_USERS + NUM_MOVIES  # 10,334\n",
    "NUM_EDGES = 100836\n",
    "EMBEDDING_DIM = 64\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "print(\"Example Dimensions:\")\n",
    "print(f\"  Users: {NUM_USERS}\")\n",
    "print(f\"  Movies: {NUM_MOVIES}\")\n",
    "print(f\"  Total Nodes: {NUM_NODES}\")\n",
    "print(f\"  Edges (ratings): {NUM_EDGES}\")\n",
    "print(f\"  Embedding Dimension: {EMBEDDING_DIM}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Dimensions:\n",
      "  Users: 610\n",
      "  Movies: 9724\n",
      "  Total Nodes: 10334\n",
      "  Edges (ratings): 100836\n",
      "  Embedding Dimension: 64\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Part 1: Input Data Shapes\n",
    "\n",
    "Before we look at the networks, let's understand the input data:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                           INPUT DATA STRUCTURES                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  1. Node Features (X)                                                       â”‚\n",
    "â”‚     Shape: (num_nodes, feature_dim) = (10334, 64)                          â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚\n",
    "â”‚     â”‚  User 0:    [0.1, 0.3, ..., 0.2]  (64,)  â”‚                           â”‚\n",
    "â”‚     â”‚  User 1:    [0.4, 0.1, ..., 0.5]  (64,)  â”‚                           â”‚\n",
    "â”‚     â”‚  ...                                     â”‚                           â”‚\n",
    "â”‚     â”‚  User 609:  [0.2, 0.8, ..., 0.1]  (64,)  â”‚                           â”‚\n",
    "â”‚     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                           â”‚\n",
    "â”‚     â”‚  Movie 0:   [0.5, 0.2, ..., 0.3]  (64,)  â”‚                           â”‚\n",
    "â”‚     â”‚  Movie 1:   [0.1, 0.9, ..., 0.4]  (64,)  â”‚                           â”‚\n",
    "â”‚     â”‚  ...                                     â”‚                           â”‚\n",
    "â”‚     â”‚  Movie 9723:[0.3, 0.1, ..., 0.7]  (64,)  â”‚                           â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  2. Edge Index                                                              â”‚\n",
    "â”‚     Shape: (2, num_edges * 2) = (2, 201672)                                â”‚\n",
    "â”‚     (We double edges for bidirectional message passing)                    â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\n",
    "â”‚     â”‚  Source: [0,    0,    1,    1,    ...]      â”‚ â† Which node sends     â”‚\n",
    "â”‚     â”‚  Target: [610,  725,  610,  892,  ...]      â”‚ â† Which node receives  â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\n",
    "â”‚     Meaning: User 0 rated Movie 0 (idx 610), Movie 115 (idx 725), etc.    â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  3. Edge Attributes (Optional)                                             â”‚\n",
    "â”‚     Shape: (num_edges * 2,) = (201672,)                                    â”‚\n",
    "â”‚     Contains: Rating values [4.5, 3.0, 5.0, ...]                           â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T09:56:31.628068Z",
     "start_time": "2026-01-13T09:56:31.608121Z"
    }
   },
   "source": [
    "# Create example tensors to show shapes\n",
    "print(\"=\" * 60)\n",
    "print(\"INPUT DATA SHAPES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Node features\n",
    "X = torch.randn(NUM_NODES, EMBEDDING_DIM)\n",
    "print(f\"\\n1. Node Features (X) include both user and movie:\")\n",
    "print(f\"   Shape: {X.shape}\")\n",
    "print(f\"   Meaning: {NUM_NODES} nodes, each with {EMBEDDING_DIM}-dimensional features\")\n",
    "print(f\"   Memory: {X.numel() * 4 / 1024:.1f} KB (float32)\")\n",
    "\n",
    "# Edge index (bidirectional)\n",
    "edge_index = torch.randint(0, NUM_NODES, (2, NUM_EDGES * 2))\n",
    "print(f\"\\n2. Edge Index created by torch.randint :\")\n",
    "print(f\"   Shape: {edge_index.shape}\")\n",
    "print(f\"   Meaning: {NUM_EDGES * 2} directed edges (bidirectional)\")\n",
    "print(f\"   Row 0 = source nodes, Row 1 = target nodes\")\n",
    "\n",
    "# Edge attributes\n",
    "edge_attr = torch.randn(NUM_EDGES * 2)\n",
    "print(f\"\\n3. Edge Attributes (ratings): created by torch.randn\")\n",
    "print(f\"   Shape: {edge_attr.shape}\")\n",
    "print(f\"   Meaning: One rating value per edge\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INPUT DATA SHAPES\n",
      "============================================================\n",
      "\n",
      "1. Node Features (X) include both user and movie:\n",
      "   Shape: torch.Size([10334, 64])\n",
      "   Meaning: 10334 nodes, each with 64-dimensional features\n",
      "   Memory: 2583.5 KB (float32)\n",
      "\n",
      "2. Edge Index created by torch.randint :\n",
      "   Shape: torch.Size([2, 201672])\n",
      "   Meaning: 201672 directed edges (bidirectional)\n",
      "   Row 0 = source nodes, Row 1 = target nodes\n",
      "\n",
      "3. Edge Attributes (ratings): created by torch.randn\n",
      "   Shape: torch.Size([201672])\n",
      "   Meaning: One rating value per edge\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§± Part 2: Matrix Factorization (Baseline)\n",
    "\n",
    "First, let's understand Matrix Factorization as a baseline - this is what your current system uses.\n",
    "\n",
    "### Architecture Diagram\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    MATRIX FACTORIZATION ARCHITECTURE                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  INPUT                           EMBEDDINGS                    OUTPUT       â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€                           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€       â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  user_id â”€â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚\n",
    "â”‚    (1,)      â”‚ User Embedding   â”‚ â”€â”€â–º user_emb â”€â”€â”                         â”‚\n",
    "â”‚              â”‚ (610, 64)        â”‚      (64,)     â”‚                         â”‚\n",
    "â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚\n",
    "â”‚                                                  â”œâ”€â”€â–º â”‚ Dot     â”‚ â”€â”€â–º rating â”‚\n",
    "â”‚  movie_id â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚    â”‚ Product â”‚    (1,)  â”‚\n",
    "â”‚    (1,)      â”‚ Movie Embedding  â”‚ â”€â”€â–º movie_emb â”€â”˜    â”‚ + Bias  â”‚          â”‚\n",
    "â”‚              â”‚ (9724, 64)       â”‚      (64,)          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚\n",
    "â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  TOTAL PARAMETERS:                                                          â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                          â”‚\n",
    "â”‚  User Embeddings:  610 Ã— 64  = 39,040                                      â”‚\n",
    "â”‚  Movie Embeddings: 9724 Ã— 64 = 622,336                                     â”‚\n",
    "â”‚  User Biases:      610 Ã— 1   = 610                                         â”‚\n",
    "â”‚  Movie Biases:     9724 Ã— 1  = 9,724                                       â”‚\n",
    "â”‚  Global Bias:      1                                                        â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚\n",
    "â”‚  TOTAL:            671,711 parameters                                      â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Point: NO GRAPH STRUCTURE USED!\n",
    "\n",
    "Matrix Factorization only looks up embeddings - it doesn't know that User A and User B both liked the same movie."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T09:59:11.456199Z",
     "start_time": "2026-01-13T09:59:11.438197Z"
    }
   },
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    \"\"\"\n",
    "    Matrix Factorization with detailed shape annotations.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding tables\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)   # (610, 64)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim) # (9724, 64)\n",
    "        \n",
    "        # Bias terms\n",
    "        self.user_bias = nn.Embedding(num_users, 1)    # (610, 1)\n",
    "        self.movie_bias = nn.Embedding(num_movies, 1)  # (9724, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1)) # (1,)\n",
    "        \n",
    "    def forward(self, user_ids, movie_ids):\n",
    "        \"\"\"\n",
    "        Forward pass with shape annotations.\n",
    "        \n",
    "        Args:\n",
    "            user_ids: (batch_size,) - e.g., (32,)\n",
    "            movie_ids: (batch_size,) - e.g., (32,)\n",
    "        \n",
    "        Returns:\n",
    "            ratings: (batch_size,) - e.g., (32,)\n",
    "        \"\"\"\n",
    "        # Step 1: Look up embeddings\n",
    "        user_emb = self.user_embedding(user_ids)    # (batch_size,) â†’ (batch_size, 64)\n",
    "        movie_emb = self.movie_embedding(movie_ids)  # (batch_size,) â†’ (batch_size, 64)\n",
    "        \n",
    "        # Step 2: Dot product (element-wise multiply then sum)\n",
    "        dot_product = (user_emb * movie_emb).sum(dim=1)  # (batch_size, 64) â†’ (batch_size,)\n",
    "        \n",
    "        # Step 3: Add biases\n",
    "        user_b = self.user_bias(user_ids).squeeze()   # (batch_size, 1) â†’ (batch_size,)\n",
    "        movie_b = self.movie_bias(movie_ids).squeeze() # (batch_size, 1) â†’ (batch_size,)\n",
    "        \n",
    "        # Step 4: Final prediction\n",
    "        rating = dot_product + user_b + movie_b + self.global_bias  # (batch_size,)\n",
    "        \n",
    "        return rating\n",
    "\n",
    "# Demo\n",
    "mf = MatrixFactorization(NUM_USERS, NUM_MOVIES, EMBEDDING_DIM)\n",
    "\n",
    "# Example: predict ratings for a batch of 32 (user, movie) pairs\n",
    "batch_user_ids = torch.randint(0, NUM_USERS, (32,))\n",
    "batch_movie_ids = torch.randint(0, NUM_MOVIES, (32,))\n",
    "\n",
    "print(\"MATRIX FACTORIZATION - Shape Flow\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Input user_ids shape:     {batch_user_ids.shape}\")\n",
    "print(f\"Input movie_ids shape:    {batch_movie_ids.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    ratings = mf(batch_user_ids, batch_movie_ids)\n",
    "\n",
    "print(f\"Output ratings shape:     {ratings.shape}\")\n",
    "print(f\"\\nTotal parameters:   {sum(p.numel() for p in mf.parameters()):,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRIX FACTORIZATION - Shape Flow\n",
      "==================================================\n",
      "Input user_ids:     torch.Size([32])\n",
      "Input movie_ids:    torch.Size([32])\n",
      "Output ratings:     torch.Size([32])\n",
      "\n",
      "Total parameters:   671,711\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T09:59:23.963737Z",
     "start_time": "2026-01-13T09:59:23.959283Z"
    }
   },
   "cell_type": "code",
   "source": "batch_user_ids",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([450, 491, 124, 296, 543, 332, 585, 226,  28, 567,  42, 243, 268,  30,\n",
       "        362, 566, 393, 230, 345, 386, 322,  83,  76, 505, 193, 205, 300, 358,\n",
       "        325, 570,  11, 246])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T09:59:39.609557Z",
     "start_time": "2026-01-13T09:59:39.604936Z"
    }
   },
   "cell_type": "code",
   "source": "batch_movie_ids",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4032, 5862, 2612, 9710, 4109, 5016,   75,  556, 7920, 8100, 8178, 8937,\n",
       "        3539, 5341, 1519, 9682, 2843, 5634, 5110, 5680, 2401, 6136, 6936, 9570,\n",
       "        3828, 7396, 4738, 9242, 3552, 8982, 8029, 5205])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T10:03:41.165915Z",
     "start_time": "2026-01-13T10:03:41.162747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_ex = nn.Embedding(32, 64)\n",
    "\n",
    "print(\"Random weights:\")\n",
    "print(embedding_ex.weight)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.7041, -1.6619,  0.6778,  ..., -0.0837,  0.8367,  0.5175],\n",
      "        [ 0.0397,  1.5307,  0.4336,  ..., -1.0611, -0.3200,  0.5048],\n",
      "        [ 0.2633,  0.0263, -1.2575,  ..., -1.8313, -1.0230, -0.9780],\n",
      "        ...,\n",
      "        [-0.8952,  0.3728,  1.3365,  ..., -0.1355,  0.2531, -0.3795],\n",
      "        [-1.9546, -0.2551,  2.0124,  ..., -0.4354, -0.3122,  0.3050],\n",
      "        [ 0.8129,  1.5046, -0.5913,  ...,  1.4424,  1.2061, -0.9679]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T10:02:09.969050Z",
     "start_time": "2026-01-13T10:02:09.966525Z"
    }
   },
   "cell_type": "code",
   "source": "ratings",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 18.3776,  -0.8742,   3.8000,   3.0006,  -5.3004,  -4.2146,  -5.9844,\n",
       "          7.3599,  -0.3993,  -2.7416,   1.7439, -10.4801,   2.9374,   1.6039,\n",
       "          1.4598,  -3.6478,  11.2099, -11.5123, -12.3864,   8.4067,   0.4564,\n",
       "         -0.4453, -15.4244,   0.1027,  -2.0579,   5.6942,   2.1892, -11.4254,\n",
       "        -15.3817, -13.5016,  -7.1818,   0.5663])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ Part 3: GCN (Graph Convolutional Network)\n",
    "\n",
    "Now let's see how GNN adds graph structure!\n",
    "\n",
    "### The Key Idea: Message Passing\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         MESSAGE PASSING CONCEPT                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Before GNN Layer:                After GNN Layer:                          â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚       User A                           User A                               â”‚\n",
    "â”‚      [0.1, 0.2]                    [0.15, 0.35]  â† Updated!                â”‚\n",
    "â”‚         â”‚                              â”‚                                    â”‚\n",
    "â”‚         â”‚ rated                        â”‚                                    â”‚\n",
    "â”‚         â–¼                              â–¼                                    â”‚\n",
    "â”‚      Movie 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Movie 1                                â”‚\n",
    "â”‚     [0.3, 0.4]                     [0.25, 0.40]  â† Updated!                â”‚\n",
    "â”‚         â–²                              â–²                                    â”‚\n",
    "â”‚         â”‚ rated                        â”‚                                    â”‚\n",
    "â”‚         â”‚                              â”‚                                    â”‚\n",
    "â”‚       User B                         User B                                 â”‚\n",
    "â”‚      [0.2, 0.5]                    [0.25, 0.45]  â† Updated!                â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Each node's new embedding = f(own embedding, neighbors' embeddings)       â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### GCN Architecture - Layer by Layer\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         GCN ARCHITECTURE                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  INPUT                                                                      â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€                                                                      â”‚\n",
    "â”‚  Node Embeddings: (10334, 64)      Edge Index: (2, 201672)                 â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚                          â”‚                                                  â”‚\n",
    "â”‚                          â–¼                                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚                      GCN Layer 1                                 â”‚      â”‚\n",
    "â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  For each node v:                                                â”‚      â”‚\n",
    "â”‚  â”‚    1. Gather neighbor embeddings: {h_u : u âˆˆ N(v)}              â”‚      â”‚\n",
    "â”‚  â”‚    2. Normalize by degree: h_u / sqrt(deg(u) * deg(v))          â”‚      â”‚\n",
    "â”‚  â”‚    3. Sum normalized embeddings                                  â”‚      â”‚\n",
    "â”‚  â”‚    4. Apply weight matrix W: (64, 64)                           â”‚      â”‚\n",
    "â”‚  â”‚    5. Add bias: (64,)                                            â”‚      â”‚\n",
    "â”‚  â”‚    6. Apply ReLU activation                                      â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  Input:  (10334, 64)                                            â”‚      â”‚\n",
    "â”‚  â”‚  Output: (10334, 64)                                            â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                          â”‚                                                  â”‚\n",
    "â”‚                          â–¼                                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚                      GCN Layer 2                                 â”‚      â”‚\n",
    "â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚      â”‚\n",
    "â”‚  â”‚  Same operations as Layer 1                                      â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  Input:  (10334, 64)                                            â”‚      â”‚\n",
    "â”‚  â”‚  Output: (10334, 64)                                            â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                          â”‚                                                  â”‚\n",
    "â”‚                          â–¼                                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚                     SPLIT EMBEDDINGS                             â”‚      â”‚\n",
    "â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  All Nodes: (10334, 64)                                         â”‚      â”‚\n",
    "â”‚  â”‚       â”‚                                                          â”‚      â”‚\n",
    "â”‚  â”‚       â”œâ”€â”€â–º User Embeddings:  (610, 64)    [nodes 0:610]         â”‚      â”‚\n",
    "â”‚  â”‚       â”‚                                                          â”‚      â”‚\n",
    "â”‚  â”‚       â””â”€â”€â–º Movie Embeddings: (9724, 64)   [nodes 610:10334]     â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                          â”‚                                                  â”‚\n",
    "â”‚                          â–¼                                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚                   RATING PREDICTION                              â”‚      â”‚\n",
    "â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  For user i, movie j:                                            â”‚      â”‚\n",
    "â”‚  â”‚    rating = dot(user_emb[i], movie_emb[j])                      â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  Input:  user_idx (batch,), movie_idx (batch,)                  â”‚      â”‚\n",
    "â”‚  â”‚  Output: ratings (batch,)                                        â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  PARAMETERS PER GCN LAYER:                                                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚\n",
    "â”‚  Weight Matrix W: 64 Ã— 64 = 4,096                                          â”‚\n",
    "â”‚  Bias Vector b:   64                                                        â”‚\n",
    "â”‚  Total per layer: 4,160                                                     â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  TOTAL GCN PARAMETERS:                                                     â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚\n",
    "â”‚  Initial Embeddings: 10334 Ã— 64 = 661,376                                  â”‚\n",
    "â”‚  GCN Layer 1:        4,160                                                  â”‚\n",
    "â”‚  GCN Layer 2:        4,160                                                  â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚\n",
    "â”‚  TOTAL:              669,696 parameters                                    â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ğŸ¯ What Are Neighbors?\n",
    "\n",
    "Neighbors are nodes connected by an edge. In your movie recommendation graph:\n",
    "\n",
    "- User's neighbors = Movies they rated\n",
    "- Movie's neighbors = Users who rated it\n",
    "\n",
    "That's it! The edges come from your rating data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "THE BIPARTITE GRAPH\n",
    "    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "         USERS                           MOVIES\n",
    "         â”€â”€â”€â”€â”€                           â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚User 1 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Movie 31 â”‚\n",
    "        â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚          â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚              â”‚                â–²  â–²\n",
    "            â”‚              â”‚                â”‚  â”‚\n",
    "            â–¼              â–¼                â”‚  â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚\n",
    "        â”‚ Movie 50 â”‚   â”‚Movie 110 â”‚        â”‚  â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚\n",
    "            â–²                              â”‚  â”‚\n",
    "            â”‚                              â”‚  â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”                          â”‚  â”‚\n",
    "        â”‚User 2 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "        â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                 â”‚\n",
    "                            â–¼                 â”‚\n",
    "                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "                       â”‚Movie 150 â”‚           â”‚\n",
    "                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”                             â”‚\n",
    "        â”‚User 3 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "                            â–¼\n",
    "                       (Movie 50 - already shown above)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ğŸ” Now Let's Answer: Who Are The Neighbors?\n",
    "\n",
    "For User 1 (row index 0):\n",
    "\n",
    "User 1's NEIGHBORS = Movies they rated\n",
    "                   = [Movie 31, Movie 50, Movie 110]\n",
    "\n",
    "In terms of row indices in your (10334, 64) matrix:\n",
    "- User 1 is at row 0\n",
    "- Movie 31 is at row 610 + movie_idx(31)\n",
    "- Movie 50 is at row 610 + movie_idx(50)\n",
    "- Movie 110 is at row 610 + movie_idx(110)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For Movie 31 (row index 610 + idx):\n",
    "\n",
    "Movie 31's NEIGHBORS = Users who rated it\n",
    "                     = [User 1, User 2, User 3]\n",
    "\n",
    "In terms of row indices:\n",
    "- Movie 31 is at row (610 + some_idx)\n",
    "- User 1 is at row 0\n",
    "- User 2 is at row 1\n",
    "- User 3 is at row 2"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The GCN Computation Step-by-Step\n",
    "\n",
    "Let's compute the new embedding for User 1 after one GCN layer:\n",
    "\n",
    "### Before GCN\n",
    "\n",
    "Initial embeddings (randomly initialized or learned):\n",
    "\n",
    "        User 1 embedding:    h_user1   = [0.1, 0.3, -0.2, ..., 0.5]    shape: (64,)\n",
    "        Movie 31 embedding:  h_movie31 = [0.4, -0.1, 0.3, ..., 0.2]    shape: (64,)\n",
    "        Movie 50 embedding:  h_movie50 = [0.2, 0.5, 0.1, ..., -0.3]    shape: (64,)\n",
    "        Movie 110 embedding: h_movie110= [-0.1, 0.2, 0.4, ..., 0.1]    shape: (64,)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### GCN Layer 1\n",
    "\n",
    "\n",
    "**Step 1: Gather neighbor embeddings**\n",
    "\n",
    "        neighbors_of_user1 = [h_movie31, h_movie50, h_movie110]  # 3 vectors, each (64,)\n",
    "\n",
    "**Step 2: Normalize by degree**\n",
    "\n",
    "        # User 1 has degree 3 (rated 3 movies)\n",
    "        # Movie 31 has degree 3 (rated by 3 users)\n",
    "        # Movie 50 has degree 2 (rated by 2 users)\n",
    "        # Movie 110 has degree 1 (rated by 1 user)\n",
    "\n",
    "\n",
    "        norm_movie31 = h_movie31 / sqrt(3 * 3)   # sqrt(deg_user1 * deg_movie31)\n",
    "        norm_movie50 = h_movie50 / sqrt(3 * 2)   # sqrt(deg_user1 * deg_movie50)\n",
    "        norm_movie110 = h_movie110 / sqrt(3 * 1) # sqrt(deg_user1 * deg_movie110)\n",
    "\n",
    "**Step 3: Sum normalized embeddings**\n",
    "\n",
    "        aggregated = norm_movie31 + norm_movie50 + norm_movie110  # shape: (64,)\n",
    "\n",
    "**Step 4: Apply weight matrix W (64, 64)**\n",
    "\n",
    "        transformed = W @ aggregated  # (64, 64) @ (64,) = (64,)\n",
    "\n",
    "**Step 5: Add bias**\n",
    "\n",
    "        with_bias = transformed + b  # (64,) + (64,) = (64,)\n",
    "\n",
    "**Step 6: Apply ReLU**\n",
    "\n",
    "        h_user1_new = ReLU(with_bias)  # shape: (64,)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### After GCN Layer:\n",
    "\n",
    "User 1's NEW embedding now contains information from:\n",
    "- Movie 31 (which they rated)\n",
    "- Movie 50 (which they rated)\n",
    "- Movie 110 (which they rated)\n",
    "\n",
    "User 1 now \"knows about\" the movies they've interacted with!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## ğŸ”„ What Happens with 2 Layers?\n",
    "\n",
    "After **Layer 1**: User 1 knows about their movies (31, 50, 110)\n",
    "\n",
    "After **Layer 2**: User 1 knows about **other users** who rated those movies!\n",
    "\n",
    "Layer 2 computation for User 1:\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "User 1's neighbors are still [Movie 31, Movie 50, Movie 110]\n",
    "\n",
    "BUT now Movie 31's embedding (after Layer 1) contains info from:\n",
    "  - User 1 (original rater)\n",
    "  - User 2 (also rated Movie 31)  â† NEW INFO!\n",
    "  - User 3 (also rated Movie 31)  â† NEW INFO!\n",
    "\n",
    "So when User 1 aggregates from Movie 31 in Layer 2,\n",
    "they indirectly get information about User 2 and User 3!\n",
    "\n",
    "This is the MAGIC of GNNs:\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "User 1 learns: \"People who liked the same movies as me also liked...\"\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ğŸ“ Visual: The Neighbor Matrix\n",
    "\n",
    "Your edge_index defines who the neighbors are:\n",
    "\n",
    "\n",
    "    edge_index = [[source nodes],\n",
    "                  [target nodes]]\n",
    "\n",
    "Example:\n",
    "\n",
    "        edge_index = [[0,    0,    0,    1,    1,    610,  610,  610],\n",
    "                      [610,  611,  612,  610,  613,  0,    1,    2  ]]\n",
    "                       â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚\n",
    "                       â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â””â”€â”€ Movie31â†’User3\n",
    "                       â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€ Movie31â†’User2\n",
    "                       â”‚     â”‚     â”‚     â”‚     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Movie31â†’User1\n",
    "                       â”‚     â”‚     â”‚     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ User2â†’Movie4\n",
    "                       â”‚     â”‚     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ User2â†’Movie31\n",
    "                       â”‚     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ User1â†’Movie3\n",
    "                       â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ User1â†’Movie2\n",
    "                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ User1â†’Movie31\n",
    "\n",
    "\n",
    "- For node 0 (User 1): neighbors = [610, 611, 612] (Movies)\n",
    "- For node 610 (Movie 31): neighbors = [0, 1, 2] (Users)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**The key insight:**\n",
    "\n",
    "GNN doesn't look at the rating values (4.5, 5.0, etc.) for the graph structureâ€”it only cares about which user rated which movie. The ratings can be used as edge weights, but the basic structure is binary: rated or not rated."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T11:48:38.212757Z",
     "start_time": "2026-01-13T11:48:38.196360Z"
    }
   },
   "source": [
    "# GCN Implementation with shape tracking\n",
    "try:\n",
    "    from torch_geometric.nn import GCNConv\n",
    "    \n",
    "    class GCNRecommender(nn.Module):\n",
    "        def __init__(self, num_users, num_movies, embedding_dim=64, num_layers=2):\n",
    "            super().__init__()\n",
    "            self.num_users = num_users\n",
    "            self.num_movies = num_movies\n",
    "            num_nodes = num_users + num_movies\n",
    "            \n",
    "            # Initial embeddings for all nodes\n",
    "            self.embedding = nn.Embedding(num_nodes, embedding_dim)  # (10334, 64)\n",
    "            \n",
    "            # GCN layers\n",
    "            self.conv1 = GCNConv(embedding_dim, embedding_dim)  # W: (64, 64)\n",
    "            self.conv2 = GCNConv(embedding_dim, embedding_dim)  # W: (64, 64)\n",
    "            \n",
    "        def forward(self, edge_index, user_idx, movie_idx, verbose=False):\n",
    "            # Get all node embeddings\n",
    "            x = self.embedding.weight  # (10334, 64)\n",
    "            if verbose: print(f\"Initial embeddings: {x.shape}\")\n",
    "            \n",
    "            # GCN Layer 1\n",
    "            x = self.conv1(x, edge_index)  # (10334, 64) â†’ (10334, 64)\n",
    "            x = torch.relu(x)\n",
    "            if verbose: print(f\"After GCN Layer 1: {x.shape}\")\n",
    "            \n",
    "            # GCN Layer 2\n",
    "            x = self.conv2(x, edge_index)  # (10334, 64) â†’ (10334, 64)\n",
    "            x = torch.relu(x)\n",
    "            if verbose: print(f\"After GCN Layer 2: {x.shape}\")\n",
    "            \n",
    "            # Split into user and movie embeddings\n",
    "            user_emb = x[:self.num_users]      # (610, 64)\n",
    "            movie_emb = x[self.num_users:]      # (9724, 64)\n",
    "            if verbose:\n",
    "                print(f\"User embeddings: {user_emb.shape}\")\n",
    "                print(f\"Movie embeddings: {movie_emb.shape}\")\n",
    "            \n",
    "            # Predict ratings for specific (user, movie) pairs\n",
    "            user_vecs = user_emb[user_idx]      # (batch,) â†’ (batch, 64)\n",
    "            movie_vecs = movie_emb[movie_idx]    # (batch,) â†’ (batch, 64)\n",
    "            if verbose:\n",
    "                print(f\"Selected user vectors: {user_vecs.shape}\")\n",
    "                print(f\"Selected movie vectors: {movie_vecs.shape}\")\n",
    "            \n",
    "            # Dot product\n",
    "            ratings = (user_vecs * movie_vecs).sum(dim=1)  # (batch, 64) â†’ (batch,)\n",
    "            if verbose: print(f\"Output ratings: {ratings.shape}\")\n",
    "            \n",
    "            return ratings\n",
    "    \n",
    "    # Demo with shape tracking\n",
    "    print(\"GCN RECOMMENDER - Shape Flow\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    gcn = GCNRecommender(NUM_USERS, NUM_MOVIES, EMBEDDING_DIM)\n",
    "    \n",
    "    # Create dummy edge index\n",
    "    dummy_edge_index = torch.randint(0, NUM_NODES, (2, 1000))\n",
    "    batch_users = torch.randint(0, NUM_USERS, (32,))\n",
    "    batch_movies = torch.randint(0, NUM_MOVIES, (32,))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ratings = gcn(dummy_edge_index, batch_users, batch_movies, verbose=True)\n",
    "    \n",
    "    print(f\"\\nTotal parameters: {sum(p.numel() for p in gcn.parameters()):,}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyTorch Geometric not installed. Showing shape flow conceptually.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN RECOMMENDER - Shape Flow\n",
      "==================================================\n",
      "Initial embeddings: torch.Size([10334, 64])\n",
      "After GCN Layer 1: torch.Size([10334, 64])\n",
      "After GCN Layer 2: torch.Size([10334, 64])\n",
      "User embeddings: torch.Size([610, 64])\n",
      "Movie embeddings: torch.Size([9724, 64])\n",
      "Selected user vectors: torch.Size([32, 64])\n",
      "Selected movie vectors: torch.Size([32, 64])\n",
      "Output ratings: torch.Size([32])\n",
      "\n",
      "Total parameters: 669,696\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â­ Part 4: LightGCN (Best for Recommendations)\n",
    "\n",
    "LightGCN is **simpler** than GCN but often **works better** for recommendations!\n",
    "\n",
    "### Key Differences from GCN:\n",
    "\n",
    "| Component | GCN | LightGCN |\n",
    "|-----------|-----|----------|\n",
    "| Weight Matrix W | âœ… Yes (64Ã—64 per layer) | âŒ No |\n",
    "| Activation (ReLU) | âœ… Yes | âŒ No |\n",
    "| Layer Combination | Use last layer | **Average all layers** |\n",
    "| Parameters | More | **Much fewer** |\n",
    "\n",
    "### LightGCN Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        LIGHTGCN ARCHITECTURE                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Layer 0 (Initial):  Eâ° = [User Emb (610,64) ; Movie Emb (9724,64)]        â”‚\n",
    "â”‚                      Shape: (10334, 64)                                     â”‚\n",
    "â”‚                            â”‚                                                â”‚\n",
    "â”‚                            â–¼                                                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚  Layer 1: EÂ¹ = Normalize(A) Ã— Eâ°                                 â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  NO weight matrix! NO activation!                                â”‚      â”‚\n",
    "â”‚  â”‚  Just: aggregate normalized neighbor embeddings                  â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  Shape: (10334, 64) â†’ (10334, 64)                               â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                                â”‚\n",
    "â”‚                            â–¼                                                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚  Layer 2: EÂ² = Normalize(A) Ã— EÂ¹                                 â”‚      â”‚\n",
    "â”‚  â”‚  Shape: (10334, 64) â†’ (10334, 64)                               â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                                â”‚\n",
    "â”‚                            â–¼                                                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚  Layer 3: EÂ³ = Normalize(A) Ã— EÂ²                                 â”‚      â”‚\n",
    "â”‚  â”‚  Shape: (10334, 64) â†’ (10334, 64)                               â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                                â”‚\n",
    "â”‚                            â–¼                                                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚              â­ LAYER COMBINATION (Key Innovation!) â­            â”‚      â”‚\n",
    "â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  E_final = (Eâ° + EÂ¹ + EÂ² + EÂ³) / 4                              â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  We AVERAGE embeddings from ALL layers, including initial!      â”‚      â”‚\n",
    "â”‚  â”‚                                                                  â”‚      â”‚\n",
    "â”‚  â”‚  Shape: (10334, 64)                                             â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                            â”‚                                                â”‚\n",
    "â”‚                            â–¼                                                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  â”‚  Split & Predict (same as GCN)                                   â”‚      â”‚\n",
    "â”‚  â”‚  Users: (610, 64), Movies: (9724, 64)                           â”‚      â”‚\n",
    "â”‚  â”‚  Rating = dot(user_emb, movie_emb)                              â”‚      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  TOTAL PARAMETERS:                                                         â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚\n",
    "â”‚  User Embeddings:  610 Ã— 64  = 39,040                                      â”‚\n",
    "â”‚  Movie Embeddings: 9724 Ã— 64 = 622,336                                     â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚\n",
    "â”‚  TOTAL:            661,376 parameters                                      â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Note: NO parameters in convolution layers!                                â”‚\n",
    "â”‚        Only the initial embeddings are learned.                            â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T12:01:47.348462Z",
     "start_time": "2026-01-13T12:01:47.281955Z"
    }
   },
   "source": [
    "# LightGCN Implementation with detailed shape tracking\n",
    "try:\n",
    "    from torch_geometric.nn import LGConv\n",
    "    \n",
    "    class LightGCNRecommender(nn.Module):\n",
    "        def __init__(self, num_users, num_movies, embedding_dim=64, num_layers=3):\n",
    "            super().__init__()\n",
    "            self.num_users = num_users\n",
    "            self.num_movies = num_movies\n",
    "            self.num_layers = num_layers\n",
    "            \n",
    "            # ONLY learnable parameters: initial embeddings\n",
    "            self.user_embedding = nn.Embedding(num_users, embedding_dim)   # (610, 64)\n",
    "            self.movie_embedding = nn.Embedding(num_movies, embedding_dim) # (9724, 64)\n",
    "            \n",
    "            # LGConv has NO learnable parameters!\n",
    "            self.convs = nn.ModuleList([LGConv() for _ in range(num_layers)])\n",
    "            \n",
    "        def forward(self, edge_index, user_idx, movie_idx, verbose=False):\n",
    "            # Combine initial embeddings\n",
    "            x = torch.cat([self.user_embedding.weight, \n",
    "                          self.movie_embedding.weight], dim=0)  # (10334, 64)\n",
    "            \n",
    "            if verbose: print(f\"Layer 0 (Initial): {x.shape}\")\n",
    "            \n",
    "            # Store all layer embeddings\n",
    "            all_embeddings = [x]\n",
    "            \n",
    "            # Propagate through layers\n",
    "            for i, conv in enumerate(self.convs):\n",
    "                x = conv(x, edge_index)  # (10334, 64) â†’ (10334, 64)\n",
    "                all_embeddings.append(x)\n",
    "                if verbose: print(f\"Layer {i+1}: {x.shape}\")\n",
    "            \n",
    "            # â­ Key: Average ALL layer embeddings\n",
    "            stacked = torch.stack(all_embeddings, dim=0)  # (4, 10334, 64)\n",
    "            if verbose: print(f\"Stacked embeddings: {stacked.shape}\")\n",
    "            \n",
    "            final_emb = stacked.mean(dim=0)  # (10334, 64)\n",
    "            if verbose: print(f\"Averaged final embedding: {final_emb.shape}\")\n",
    "            \n",
    "            # Split\n",
    "            user_emb = final_emb[:self.num_users]    # (610, 64)\n",
    "            movie_emb = final_emb[self.num_users:]   # (9724, 64)\n",
    "            if verbose:\n",
    "                print(f\"User embeddings: {user_emb.shape}\")\n",
    "                print(f\"Movie embeddings: {movie_emb.shape}\")\n",
    "            \n",
    "            # Predict\n",
    "            user_vecs = user_emb[user_idx]      # (batch, 64)\n",
    "            movie_vecs = movie_emb[movie_idx]   # (batch, 64)\n",
    "            ratings = (user_vecs * movie_vecs).sum(dim=1)  # (batch,)\n",
    "            \n",
    "            if verbose: print(f\"Output ratings: {ratings.shape}\")\n",
    "            \n",
    "            return ratings\n",
    "    \n",
    "    # Demo\n",
    "    print(\"LIGHTGCN RECOMMENDER - Shape Flow\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    lgcn = LightGCNRecommender(NUM_USERS, NUM_MOVIES, EMBEDDING_DIM, num_layers=3)\n",
    "    \n",
    "    dummy_edge_index = torch.randint(0, NUM_NODES, (2, 1000))\n",
    "    batch_users = torch.randint(0, NUM_USERS, (32,))\n",
    "    batch_movies = torch.randint(0, NUM_MOVIES, (32,))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ratings = lgcn(dummy_edge_index, batch_users, batch_movies, verbose=True)\n",
    "    \n",
    "    print(f\"\\nTotal parameters: {sum(p.numel() for p in lgcn.parameters()):,}\")\n",
    "    print(\"(Note: All parameters are in embeddings, NOT in conv layers!)\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyTorch Geometric not installed.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHTGCN RECOMMENDER - Shape Flow\n",
      "==================================================\n",
      "Layer 0 (Initial): torch.Size([10334, 64])\n",
      "Layer 1: torch.Size([10334, 64])\n",
      "Layer 2: torch.Size([10334, 64])\n",
      "Layer 3: torch.Size([10334, 64])\n",
      "Stacked embeddings: torch.Size([4, 10334, 64])\n",
      "Averaged final embedding: torch.Size([10334, 64])\n",
      "User embeddings: torch.Size([610, 64])\n",
      "Movie embeddings: torch.Size([9724, 64])\n",
      "Output ratings: torch.Size([32])\n",
      "\n",
      "Total parameters: 661,376\n",
      "(Note: All parameters are in embeddings, NOT in conv layers!)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Part 5: Complete Shape Summary\n",
    "\n",
    "### Input â†’ Output Flow for All Models\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    COMPLETE SHAPE FLOW SUMMARY                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  INPUTS:                                                                    â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€                                                                    â”‚\n",
    "â”‚  â€¢ edge_index:  (2, 201672)     - Graph structure (which nodes connect)    â”‚\n",
    "â”‚  â€¢ user_idx:    (batch_size,)   - Which users to predict for               â”‚\n",
    "â”‚  â€¢ movie_idx:   (batch_size,)   - Which movies to predict for              â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  MATRIX FACTORIZATION:                                                      â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚\n",
    "â”‚  user_idx (32,) â”€â”€â–º Embedding â”€â”€â–º user_emb (32, 64) â”€â”€â”                    â”‚\n",
    "â”‚                                                        â”œâ”€â”€â–º rating (32,)   â”‚\n",
    "â”‚  movie_idx (32,) â”€â–º Embedding â”€â”€â–º movie_emb (32, 64) â”€â”˜                    â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  GCN / GraphSAGE / GAT:                                                    â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚\n",
    "â”‚  All nodes (10334, 64) â”€â”€â–º GNN Layers â”€â”€â–º All nodes (10334, 64)            â”‚\n",
    "â”‚                                               â”‚                             â”‚\n",
    "â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\n",
    "â”‚                                    â–¼                     â–¼                  â”‚\n",
    "â”‚                            Users (610, 64)      Movies (9724, 64)          â”‚\n",
    "â”‚                                    â”‚                     â”‚                  â”‚\n",
    "â”‚                           user_idx (32,)        movie_idx (32,)            â”‚\n",
    "â”‚                                    â”‚                     â”‚                  â”‚\n",
    "â”‚                                    â–¼                     â–¼                  â”‚\n",
    "â”‚                            (32, 64)      Â·        (32, 64)                 â”‚\n",
    "â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n",
    "â”‚                                              â–¼                              â”‚\n",
    "â”‚                                        rating (32,)                         â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  LIGHTGCN (with layer averaging):                                          â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚\n",
    "â”‚  Layer 0: (10334, 64) â”€â”                                                   â”‚\n",
    "â”‚  Layer 1: (10334, 64) â”€â”¼â”€â”€â–º Stack (4, 10334, 64) â”€â”€â–º Mean â”€â”€â–º (10334, 64) â”‚\n",
    "â”‚  Layer 2: (10334, 64) â”€â”¤                                          â”‚        â”‚\n",
    "â”‚  Layer 3: (10334, 64) â”€â”˜                                   [same as GCN]   â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T12:02:55.435614Z",
     "start_time": "2026-01-13T12:02:55.430098Z"
    }
   },
   "source": [
    "# Create a comprehensive shape table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TENSOR SHAPES AT EACH STAGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "shapes_data = [\n",
    "    [\"INPUT\", \"edge_index\", \"(2, 201672)\", \"Graph connectivity\"],\n",
    "    [\"INPUT\", \"user_idx (batch)\", \"(32,)\", \"User indices to predict\"],\n",
    "    [\"INPUT\", \"movie_idx (batch)\", \"(32,)\", \"Movie indices to predict\"],\n",
    "    [\"\", \"\", \"\", \"\"],\n",
    "    [\"EMBEDDING\", \"Initial node features\", \"(10334, 64)\", \"All users + movies\"],\n",
    "    [\"EMBEDDING\", \"User embeddings\", \"(610, 64)\", \"Learned user representations\"],\n",
    "    [\"EMBEDDING\", \"Movie embeddings\", \"(9724, 64)\", \"Learned movie representations\"],\n",
    "    [\"\", \"\", \"\", \"\"],\n",
    "    [\"GNN LAYER\", \"Input to layer\", \"(10334, 64)\", \"All node embeddings\"],\n",
    "    [\"GNN LAYER\", \"Output from layer\", \"(10334, 64)\", \"Updated embeddings\"],\n",
    "    [\"GNN LAYER\", \"Weight matrix (GCN)\", \"(64, 64)\", \"Learnable transformation\"],\n",
    "    [\"\", \"\", \"\", \"\"],\n",
    "    [\"LIGHTGCN\", \"Stacked layers\", \"(4, 10334, 64)\", \"All layer outputs\"],\n",
    "    [\"LIGHTGCN\", \"Averaged\", \"(10334, 64)\", \"Final embeddings\"],\n",
    "    [\"\", \"\", \"\", \"\"],\n",
    "    [\"PREDICTION\", \"Selected user embs\", \"(32, 64)\", \"Batch of user vectors\"],\n",
    "    [\"PREDICTION\", \"Selected movie embs\", \"(32, 64)\", \"Batch of movie vectors\"],\n",
    "    [\"PREDICTION\", \"Dot product\", \"(32, 64)\", \"Element-wise multiply\"],\n",
    "    [\"OUTPUT\", \"Ratings\", \"(32,)\", \"Predicted ratings\"],\n",
    "]\n",
    "\n",
    "print(f\"{'Stage':<12} {'Tensor':<25} {'Shape':<18} {'Description'}\")\n",
    "print(\"-\" * 80)\n",
    "for row in shapes_data:\n",
    "    print(f\"{row[0]:<12} {row[1]:<25} {row[2]:<18} {row[3]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TENSOR SHAPES AT EACH STAGE\n",
      "================================================================================\n",
      "Stage        Tensor                    Shape              Description\n",
      "--------------------------------------------------------------------------------\n",
      "INPUT        edge_index                (2, 201672)        Graph connectivity\n",
      "INPUT        user_idx (batch)          (32,)              User indices to predict\n",
      "INPUT        movie_idx (batch)         (32,)              Movie indices to predict\n",
      "                                                          \n",
      "EMBEDDING    Initial node features     (10334, 64)        All users + movies\n",
      "EMBEDDING    User embeddings           (610, 64)          Learned user representations\n",
      "EMBEDDING    Movie embeddings          (9724, 64)         Learned movie representations\n",
      "                                                          \n",
      "GNN LAYER    Input to layer            (10334, 64)        All node embeddings\n",
      "GNN LAYER    Output from layer         (10334, 64)        Updated embeddings\n",
      "GNN LAYER    Weight matrix (GCN)       (64, 64)           Learnable transformation\n",
      "                                                          \n",
      "LIGHTGCN     Stacked layers            (4, 10334, 64)     All layer outputs\n",
      "LIGHTGCN     Averaged                  (10334, 64)        Final embeddings\n",
      "                                                          \n",
      "PREDICTION   Selected user embs        (32, 64)           Batch of user vectors\n",
      "PREDICTION   Selected movie embs       (32, 64)           Batch of movie vectors\n",
      "PREDICTION   Dot product               (32, 64)           Element-wise multiply\n",
      "OUTPUT       Ratings                   (32,)              Predicted ratings\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Part 6: Q: What is the output? Embeddings or Ratings?\n",
    "\n",
    "**A: BOTH!** Here's the two-stage process:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  STAGE 1: COMPUTE EMBEDDINGS (happens once per training step)              â”‚\n",
    "â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Input: Graph (edge_index)                                                  â”‚\n",
    "â”‚  Output: Embeddings for ALL users (610, 64) and ALL movies (9724, 64)      â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  This is the \"forward pass through GNN\"                                    â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  STAGE 2: PREDICT RATINGS (happens for each user-movie pair)               â”‚\n",
    "â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Input: user_idx, movie_idx + embeddings from Stage 1                      â”‚\n",
    "â”‚  Output: rating = dot(user_embedding, movie_embedding)                     â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  This is just a dot product - very fast!                                   â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Why This Design?\n",
    "\n",
    "1. **Efficiency**: Compute embeddings once, predict many ratings\n",
    "2. **Flexibility**: Embeddings can be used for other tasks (similarity, clustering)\n",
    "3. **Scalability**: For inference, pre-compute and cache all embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the two-stage process\n",
    "print(\"TWO-STAGE PREDICTION PROCESS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ“ STAGE 1: Compute all embeddings (expensive, do once)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Simulate GNN forward pass\n",
    "all_user_embeddings = torch.randn(NUM_USERS, EMBEDDING_DIM)   # (610, 64)\n",
    "all_movie_embeddings = torch.randn(NUM_MOVIES, EMBEDDING_DIM) # (9724, 64)\n",
    "\n",
    "print(f\"User embeddings computed: {all_user_embeddings.shape}\")\n",
    "print(f\"Movie embeddings computed: {all_movie_embeddings.shape}\")\n",
    "print(f\"Total embeddings in memory: {(all_user_embeddings.numel() + all_movie_embeddings.numel()) * 4 / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nğŸ“ STAGE 2: Predict ratings (cheap, do many times)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Predict for a single (user, movie) pair\n",
    "user_id = 42\n",
    "movie_id = 100\n",
    "\n",
    "user_vec = all_user_embeddings[user_id]   # (64,)\n",
    "movie_vec = all_movie_embeddings[movie_id] # (64,)\n",
    "rating = torch.dot(user_vec, movie_vec)    # scalar\n",
    "\n",
    "print(f\"Predict rating for User {user_id}, Movie {movie_id}:\")\n",
    "print(f\"  user_vec shape:  {user_vec.shape}\")\n",
    "print(f\"  movie_vec shape: {movie_vec.shape}\")\n",
    "print(f\"  rating (dot product): {rating.item():.3f}\")\n",
    "\n",
    "# Predict for a batch\n",
    "print(\"\\nğŸ“ Batch prediction (efficient for training):\")\n",
    "batch_users = torch.tensor([0, 1, 2, 42, 100])\n",
    "batch_movies = torch.tensor([50, 100, 200, 300, 400])\n",
    "\n",
    "batch_user_vecs = all_user_embeddings[batch_users]    # (5, 64)\n",
    "batch_movie_vecs = all_movie_embeddings[batch_movies]  # (5, 64)\n",
    "batch_ratings = (batch_user_vecs * batch_movie_vecs).sum(dim=1)  # (5,)\n",
    "\n",
    "print(f\"  Batch size: {len(batch_users)}\")\n",
    "print(f\"  Output ratings shape: {batch_ratings.shape}\")\n",
    "print(f\"  Ratings: {batch_ratings.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Summary: Architecture Comparison Table\n",
    "\n",
    "| Model | Layer Operations | Params per Layer | Total Params | Key Feature |\n",
    "|-------|-----------------|------------------|--------------|-------------|\n",
    "| **Matrix Factorization** | Embedding lookup only | N/A | 671K | No graph structure |\n",
    "| **GCN** | Aggregate + Linear + ReLU | 4,160 | 669K | Weight matrix per layer |\n",
    "| **GraphSAGE** | Sample + Aggregate + Linear | 8,256 | 677K | Sampling for scalability |\n",
    "| **GAT** | Attention + Aggregate + Linear | 16,640 | 693K | Learns neighbor importance |\n",
    "| **LightGCN** | Aggregate only (no weights!) | **0** | **661K** | Simplest, often best |\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **All GNNs output embeddings first, then predict ratings via dot product**\n",
    "2. **LightGCN is simplest but often works best for recommendations**\n",
    "3. **The graph structure allows information to flow between users who rated similar movies**\n",
    "4. **Multi-layer = multi-hop information (2 layers = friends of friends)**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T12:04:07.469060Z",
     "start_time": "2026-01-13T12:04:07.325414Z"
    }
   },
   "source": [
    "# Final visualization: How many layers = how many hops\n",
    "def visualize_hops():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for i, (ax, layers) in enumerate(zip(axes, [1, 2, 3])):\n",
    "        ax.set_xlim(0, 10)\n",
    "        ax.set_ylim(0, 6)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{layers} GNN Layer(s) = {layers}-Hop Information', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Central node\n",
    "        ax.scatter([5], [3], s=500, c='red', zorder=10, label='Target User')\n",
    "        ax.text(5, 3, 'U', ha='center', va='center', fontsize=12, color='white', fontweight='bold')\n",
    "        \n",
    "        if layers >= 1:\n",
    "            # 1-hop neighbors (movies)\n",
    "            for j, (x, y) in enumerate([(3, 4), (7, 4), (5, 5)]):\n",
    "                ax.scatter([x], [y], s=300, c='orange', zorder=5)\n",
    "                ax.text(x, y, 'M', ha='center', va='center', fontsize=10, color='white')\n",
    "                ax.plot([5, x], [3, y], 'gray', linewidth=1, zorder=1)\n",
    "        \n",
    "        if layers >= 2:\n",
    "            # 2-hop neighbors (other users)\n",
    "            for x, y in [(1, 5), (3, 5.5), (7, 5.5), (9, 5)]:\n",
    "                ax.scatter([x], [y], s=200, c='blue', alpha=0.7, zorder=3)\n",
    "                ax.text(x, y, 'U', ha='center', va='center', fontsize=8, color='white')\n",
    "        \n",
    "        if layers >= 3:\n",
    "            # 3-hop neighbors (their movies)\n",
    "            for x, y in [(0.5, 4), (2, 4.5), (8, 4.5), (9.5, 4)]:\n",
    "                ax.scatter([x], [y], s=150, c='green', alpha=0.5, zorder=2)\n",
    "                ax.text(x, y, 'M', ha='center', va='center', fontsize=7, color='white')\n",
    "        \n",
    "        # Legend\n",
    "        ax.text(5, 0.5, f'User knows about {layers}-hop neighbors', ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"How GNN Layers Expand Information Flow:\")\n",
    "print(\"=\"*50)\n",
    "visualize_hops()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How GNN Layers Expand Information Flow:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ Next Steps\n",
    "\n",
    "Now that you understand the architectures:\n",
    "\n",
    "0. **Run the GCN_Step_by_Step notebook**\n",
    "1. Analyze the actual movie data. Use a small part of this data and see what happens inside GCN layer.\n",
    "1. **Run the main learning notebook** (`GNN_Recommender_sÄ°mple.ipynb`) to see these in action\n",
    "2. **Experiment with layer counts** - try 1, 2, 3, 4 layers\n",
    "3. **Compare embeddings** - visualize with t-SNE to see clustering\n",
    "4. **Add node features** - incorporate movie genres for better cold-start handling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
